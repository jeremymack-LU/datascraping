<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Data Scraping with R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Jeremy Mack" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
    <link rel="stylesheet" href="default-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: center, middle, inverse, title-slide

## R tutorial: data scraping
#### Jeremy Mack
#### Lehigh University - Digital Scholarship Team
&lt;center&gt;&lt;img src="./images/webscrape4.png" alt="RStudio" height=150/&gt;&lt;/center&gt;
&lt;br/&gt;&lt;br/&gt;

---
### About this tutorial

 * This tutorial will focus on **data scraping** using R.
 
--
 
 * It uses an example of extracting COVID-19 data from the daily report issued by the PA Department of Health.
 
---
class: center, middle, inverse

#### First, what is data scraping?
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;

---
#### Data scraping

&lt;center&gt;&lt;img src="./images/webscrape1.png" alt="RStudio" height=175/&gt;&lt;/center&gt;

 * **Data scraping** is a technique in which a computer program extracts data from human-readable output coming from another program.
 
--

 * One form of data scraping is referred to as **web scraping**.

---
#### Data scraping

&lt;center&gt;&lt;img src="./images/webscrape2.png" alt="RStudio" height=175/&gt;&lt;/center&gt;

 * **Data scraping** is a technique in which a computer program extracts data from human-readable output coming from another program.

 * One form of data scraping is referred to as **web scraping**.
 
 * Web scraping uses tools to extract data from a web page by accessing its **text-based mark-up language** (i.e., HTML and XHTML).
 
--
 
 * In other words, we are taking existing **HTML data**, using a web scraper (**R**) to identify the data, and convert it into a useful format (**.txt file**).

---
class: center, middle, inverse

#### Data scraping in R
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;

---
#### Data scraping in R

.pull-right2[
&lt;center&gt;&lt;img src="./images/rvest.png" alt="RStudio" height=350/&gt;&lt;/center&gt;]

.pull-left2[
Data scraping in R can be broken down into three basic steps:
{{content}}]

--

 1. Identify website XPath
 {{content}}
 
--

 2. Extract data using **rvest** package
 {{content}}
 
--
 
 3. Create and export data frame
 {{content}}

---
class: center, middle, inverse

#### Step 1: Data scraping in R
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;

---
#### Step 1: Identify website XPath

&lt;center&gt;&lt;img src="./images/xpath.png" alt="RStudio" height=175/&gt;&lt;/center&gt;

 * R uses an **XPath** to locate elements on a web page.
 
--
 
 * XPath, short for XML path, uses an **XML path expression** to locate items.
 
--

 * We could write our own XPath, but instead, we'll use a browser window, to identify the exact XPath we're interested in.

---
#### Step 1: Identify website XPath

.pull-right2[
&lt;center&gt;&lt;img src="./images/xpath2.png" alt="RStudio" width=400/&gt;&lt;/center&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;center&gt;&lt;img src="./images/xpath3.png" alt="RStudio" width=400/&gt;&lt;/center&gt;

]

.pull-left2[Basic steps to identify an XPath:
 
 1. Open web page in Google Chrome.
  
 2. Right click on the item you're interested in scraping and click **Inspect**.
  
 3. In the **Elements portion Inspector window**, mouse over each line until the entire talbe is highlighted.
  
 4. Right click on the line, click **Copy**, and then click **Copy XPath**
  ]

---
#### Step 1: Identify website XPath

&lt;iframe width="750" height="500" src="https://www.youtube.com/embed/KAqxWsE29_c?VQ=HD1080" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

---
class: center, middle, inverse

#### Step 2: Extract data using *rvest* package
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;

---
#### Step 2: Extract data using *rvest* package

.tiny[
* Load necessary packages

```r
library(tidyverse) # Load core Tidyverse packages, includeing dplyr
library(rvest)     # Additional Tidyverse packages for web scraping
library(xml2)      # Package to work with XML files
```

* Set urls for PA Deparment of Health web pages (cases and deaths)

```r
url1 &lt;- "https://www.health.pa.gov/topics/disease/coronavirus/Pages/Cases.aspx"
url2 &lt;- "https://www.health.pa.gov/topics/disease/coronavirus/Pages/Death-Data.aspx"
```

* Set XPaths to the tables that were copied from each web page

```r
xpath1 &lt;- '//*[@id="ctl00_PlaceHolderMain_PageContent__ControlWrapper_RichHtmlField"]/table[5]'
xpath2 &lt;- '//*[@id="ctl00_PlaceHolderMain_PageContent__ControlWrapper_RichHtmlField"]/table'
```
]

---
#### Step 2: Extract data using *rvest* package

.tiny[
* Scrape and create data frame for COVID-19 case data

```r
cases &lt;- url1 %&gt;%                # Scrape data
  read_html() %&gt;%
  html_nodes(xpath=xpath1) %&gt;%
  html_table()
cases &lt;- cases[[1]]              # Select table number
cases &lt;- cases[-1,]              # Remove first row, which contains table headers
cases &lt;- cases[,c(1:2)]          # Select column for County and Cases
names(cases) &lt;- c("County",
                  "Covid_cases") # Add column names

head(cases, 5)
```

```
##      County Covid_cases
## 2     Adams         263
## 3 Allegheny        1965
## 4 Armstrong          64
## 5    Beaver         599
## 6   Bedford          42
```
]

---
#### Step 2: Extract data using *rvest* package

.tiny[
* Scrape and create data frame for COVID-19 death data

```r
deaths &lt;- url2 %&gt;%                 # Scrape data
  read_html() %&gt;%
  html_nodes(xpath=xpath2) %&gt;%
  html_table()
deaths&lt;- deaths[[1]]               # Select table number
deaths&lt;- deaths[-1,]               # Remove first row, which contains table headers
deaths &lt;- deaths[,c(1:2)]          # Select column for County and Deaths
names(deaths) &lt;- c("County",
                   "Covid_deaths") # Add column names
deaths[35,1] &lt;- "McKean"           # Fix name for McKean County (not Mckean)

head(deaths, 5)
```

```
##      County Covid_deaths
## 2     Adams            8
## 3 Allegheny          166
## 4 Armstrong            5
## 5    Beaver           74
## 6   Bedford            2
```
]

---
class: center, middle, inverse

#### Step 3: Create and export data frame
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;

---
#### Step 3: Create and export data frame

.tiny[
* Merge both data frames

```r
df &lt;- merge(cases, deaths, by="County", all.x=TRUE) # Merge by County

df &lt;- df %&gt;%                                        # Set data structure for variables
  mutate(County=as.factor(County),
         Covid_cases=as.numeric(Covid_cases),
         Covid_deaths=as.numeric(gsub(",","",Covid_deaths))) %&gt;%
  mutate(Covid_deaths=ifelse(is.na(Covid_deaths),0,Covid_deaths))

head(df, 5)
```

```
##      County Covid_cases Covid_deaths
## 1     Adams         263            8
## 2 Allegheny        1965          166
## 3 Armstrong          64            5
## 4    Beaver         599           74
## 5   Bedford          42            2
```
]

---
#### Step 3: Create and export data frame

.tiny[
* Export to text file

```r
write.table(df,
            "/Users/jeremymack/Desktop/COVID19_data.txt",
            sep=",",
            row.names=FALSE)
```

* Note, you'll need to change *"/Users/jeremymack/Desktop/"* in the above filepath, to your own working directory.
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
